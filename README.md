# AutoPark Vision: AI 기반 스마트 자율주차 로봇 시스템

**ROS 2 + YOLOv8 + OCR 기반으로, 차량 번호판 인식 → 차량 분류 → 주차 및 출차까지 수행하는 자율주차 시스템을 구현했습니다.**
**전기차 수요 증가와 주차 공간 부족 문제를 해결하고자, `인식-판단-행동` 전 과정을 자동화한 TurtleBot 기반 주차 로봇 프로토타입을 구축했습니다.**

* 📅 **개발 기간**: 2025.06.25 \~ 07.04 (10일)
* 🧑‍🤝‍🧑 **인원 구성**: 7명
  **(본인 역할: YOLO 학습(주차공간 object detection), 성능 측정 및 경량화, 경고음 통합)**
* 🛠 **사용 기술**: ROS 2, YOLOv8, EasyOCR, OAK-D Pro, TurtleBot4, RPLiDAR, InfluxDB, PyQt
* ✅ **주요 기능**: 차량 번호판 인식 및 분류, 정밀 주차/출차, 실시간 GUI 및 DB 연동, 압축 이미지 기반 경량화

---

## 📑 프로젝트 개요

* **주제**: AutoPark Vision (스마트 자율주차 시스템)
* **목표**: 주차 수요 증가와 인력 문제를 해소하기 위한 자율주차 로봇 시스템 개발
* **팀원**: 7명

**🧑‍🤝‍🧑 팀원 역할 분담**

> | 이름           | 역할                                           |
> | ------------ | -------------------------------------------- |
> | **이세현(작성자)** | **YOLO 학습(주차공간 object detection), 성능 측정 및 경량화, 입출차 경고음 통합** |
> | 강인우          | OCR 기반 번호판 인식, Depth-TF 연동, Navi 연계          |
> | 이형연          | GUI 설계 및 OCR-GUI 통합, InfluxDB 구조 설계          |
> | 정서윤          | [팀장]SLAM 및 Navigation, 주차금지 경고음 통합, GUI-SLAM 통합         |
> | 나승원          | YOLO 학습(번호판 object detection)          |
> | 이동기          | 자료조사 및 차량 훈련 학습          |
> | 홍진규          | 자료조사, 영상편집         |


<br>

**📅 작업 일정**

> | 기간           | 작업 내용                         |
> | ------------ | ----------------------------- |
> | 06/25 \~ 06/26 | 기획 및 역할 분담                    |
> | 06/27 \~ 06/29 | YOLO 학습 및 OCR 파이프라인 구성        |
> | 06/30 \~ 07/01 | Navi 및 Depth-TF 연동, 통합 GUI 구현 |
> | 07/01 \~ 07/02 | 통합 테스트              |
> | 07/03 \~ 07/04  | 최종 발표 및 보고서 제출                |

<br>
<br>

**💡 본인 주요 기여**

### 1️⃣ YOLOv8 기반 주차 공간 탐지 모델 구축

* 주차 가능 영역, 금지 사인 등을 인식하는 커스텀 YOLOv8 모델 학습
* 여러 버전(YOLOv5, v8 등) 비교 후 성능과 속도 고려해 `YOLOv8n` 선정
* OAK-D 카메라의 출력 이미지를 `320x320`으로 조정하고,<br>
  **YOLO 학습 시에도 동일한 해상도로 리사이즈 없이 학습**하도록 설정해 리소스 최적화

### 2️⃣ 시스템 부하 경량화 및 실시간 측정 도구 개발

* SLAM + Navigation 부하를 고려하여 OAK-D 설정(FPS, 해상도 등) 최적화
* 이미지 압축(`compressed image`) 구조로 전환해

  * 단순 YOLO 경우: **네트워크 트래픽 90% 절감**
  * YOLO + Depth 병합 경우: **30% 절감 효과**
* 기존 `htop`, `iftop` 대신 Python 기반 리소스 측정 도구(`raspi_monitor.py`) 구현<br>
  → 전체 CPU 사용량, 특정 PID_CPU 사용량, 메모리, 네트워크 트래픽을 실시간 기록하여 `CSV`로 정량 분석
* `image_transport` 기반 압축 방식 채택<br>
  → `i_low_bandwidth` 대신 사용한 이유는 **타임스탬프 동기화의 안정성 확보**

### 3️⃣ 입출차 수행 경고음 출력 기능 구현

* 입·출차 전체 프로세스에서 **threading 기반 비동기 경고음 출력**
  * 사운드 재생 타이밍 정밀 제어를 위해 `rotation_test.py` 테스트 코드를 통해 **동기 및 비동기 방식 모두 실험 진행**
  * 별도 노드를 구성해 `threading` 기반 비동기 출력 방식 검증
  * waypoint 전체 주행 없이도 **단일 회전 동작만으로 경고음 출력 실험 가능**
* 테스트 결과를 바탕으로 실제 waypoint 주행 로직에 비동기 재생 방식 통합<br>
  → 사용자에게 **시각 + 청각적 상태 인식** 동시 제공
---

## 1. 개발 배경 및 기획

전기차 시장이 급속히 성장하면서 실시간 주차 공간 확보와 효율적 운영에 대한 수요가 증가하고 있습니다. 특히 무인 자율주차 서비스는 노동력 절감과 안전성, 편의성 측면에서 주목받고 있습니다.

**AutoPark Vision 프로젝트**는 TurtleBot4와 OAK-D, LiDAR를 이용하여 차량 번호판 인식, 차종 분류, 위치 판단, 그리고 SLAM 기반 자율주차·출차 기능을 통합한 **스마트 자율주차 로봇 시스템**을 구현하는 것이 목표였습니다.

### 🔧 핵심 기능

1. 차량 번호판 인식 및 차종 분류 (YOLO + OCR)
2. 주차 위치 판단 및 자율이동 (Nav2 + SLAM + TF)
3. GUI 기반 입출차 및 DB 기록 관리

### 🧭 프로세스

![시스템 플로우 다이어그램](https://github.com/user-attachments/assets/example_autopark_diagram.jpg)

먼저 `detect_car_info.py`에서 yolo로 번호판을 감지(차종 구분), 이후 감지한 번호판만 crop해서 easyocr을 해서 번호판 추출. 추출과정에서 정확도가 떨어져 이를 정규표현식 필터링을 통해 해결. 해당 추출데이터들을 parking_gui에 발행. gui에서 이를 확인. `sc_follow_waypoint.py`를 통해 navi 경로를 설정해주고 gui에서 주차버튼을 활성화시키면 주차기능 실행.
`yolo_detect.py`에서 yolo와 depth기능을 통해 주차장의 구역 sign을 감지.
이때 waypoint 주행 중 go_to_pose_blocking함수를 통해 주차구역 마킹하는 코드 `detect_ps_front.py`가 navigator.isTaskComplete가 완료될때 주차sign을 탐지해서 정밀 주차 좌표를 마킹하도록 구현. 이후 `sc_follow_waypoint.py` 남은 동작실행으로 초기 위치복귀 및 도킹
| 🚗 **입차 (주차) 프로세스** | 🏁 **출차 프로세스** |
| -------------------------- | -------------------- |
| 1. 차량 진입 후 번호판 감지 (YOLO) <br>&emsp;&emsp;&emsp;&emsp;↓<br> 2. EasyOCR로 번호 추출 및 차종 분류 <br>&emsp;&emsp;&emsp;&emsp;↓<br> 3. GUI에서 ‘주차’ 버튼 클릭 <br>&emsp;&emsp;&emsp;&emsp;↓<br> 4. Navi 기반 waypoint 주행 시작 <br>&emsp;&emsp;&emsp;&emsp;↓<br> 5. 주행 중 YOLO+Depth로 주차 사인 탐지 <br>&emsp;&emsp;&emsp;&emsp;↓<br> 6. `BasicNavigator.getFeedback()`으로 waypoint 도착 후 정밀 위치 마킹 <br>&emsp;&emsp;&emsp;&emsp;↓<br> 7. **마킹 위치 이동 및 180도 회전 + 경고음 출력** <br>&emsp;&emsp;&emsp;&emsp;↓<br> 8. 복귀 이동 → Docking | 1. GUI에 출차 차량번호 입력 <br>&emsp;&emsp;&emsp;&emsp;↓<br> 2. DB에서 해당 차량 주차 위치 확인 <br>&emsp;&emsp;&emsp;&emsp;↓<br> 3. 출차 TurtleBot이 waypoint 주행 시작 <br>&emsp;&emsp;&emsp;&emsp;↓<br> 4. 차량 앞 도착 후 **180도 회전 + 경고음 출력** <br>&emsp;&emsp;&emsp;&emsp;↓<br> 5. 차량 출차 <br>&emsp;&emsp;&emsp;&emsp;↓<br> 6. 지정 위치 이동 → 복귀 → Docking |



---

## 2. 사용 장비 & 기술 스택

![image](https://github.com/user-attachments/assets/example_autopark_tech.jpg)

| 분류     | 기술                                        |
| ------ | ----------------------------------------- |
| 언어     | Python                                    |
| 로봇 제어  | ROS 2 (Humble), Nav2, TurtleBot4, RPLIDAR |
| 객체 인식  | YOLOv8 (주차공간/차량 번호판/차종)                   |
| 문자 인식  | EasyOCR (번호판 추출 및 정규표현식 필터링)              |
| 센서     | OAK-D Pro (RGB-D), RPLiDAR                |
| GUI 설계 | PyQt                                      |
| DB 기록  | InfluxDB (차량 입출차 시계열 기록)                  |
| 최적화    | 압축 이미지 전송 (image_transport), Oak-D Pro.yaml 파라미터 설정               |

---

## 3. 주요 기능 구현 과정

### 3-1. 🚘 차량 번호판 인식 및 차종 분류

#### 📌 기술 스택 및 구조

* **YOLOv8** → 번호판 객체 탐지 및 차종 분류 (EV, 일반, 장애인차량)
* **EasyOCR** → 번호판 영역 내 문자 인식 및 유효성 검사
* 차량 정보: `{"type": "disabled", "car_plate": "123가4568"}` 형태로 DB 저장

#### ⚙️ 구현 내용

* YOLOv8을 사용하여 4클래스 번호판/차종 구분 모델 학습
* EasyOCR 결과에 정규표현식(`\d{2,3}[가-힣]\d{4}`) 적용
* OCR/차종 정보를 기반으로 적합한 주차 공간(A-1\~C-2) 결정

---

### 3-2. 📏 Depth-TF 기반 주차 위치 정밀 제어

#### 📌 기술 스택 및 구조

* **OAK-D** Depth 정보를 이용한 중심 거리 추정
* **TF 좌표 변환** (`do_transform_point`)을 통해 로봇 좌표계 기준 정밀 주차
* **Namespace 기반 TF 리매핑** → TF 충돌 방지

#### ⚙️ 구현 내용

* `detect_yolo.py`에서 YOLO 탐지 결과(`/detect/object_info`)를 구독하여 주차 사인 인식
* 중심 좌표의 단일 픽셀 Depth는 노이즈 영향 등으로 불안정,
  → **중심 `3x3` 영역의 유효값들의 중앙값 Depth**를 계산해 안정적인 거리 추정
* 추정된 Depth를 바탕으로 `pixel_to_3d()` 함수로 카메라 기준 3D 좌표 복원
* 이후 `lookup_transform()`으로 `camera_link → map` 프레임 변환 정보 획득
* 최종적으로 `do_transform_point()`를 통해 실제 위치를 map 기준으로 변환
* 로봇 중심 기준 `-0.5m` 오프셋을 적용해, **탐지된 표지판보다 약간 앞에 정확히 주차되도록 보정 처리**
* **다중 TurtleBot 사용 시**, 각 로봇의 TF 충돌 방지를 위해 robot_namespace로 리매핑 처리
  → 좌표 변환 정확도 확보 및 로컬 TF 충돌 방지

---

### 3-3. 🧭 SLAM 기반 입차/출차 자율주행

#### 📌 기술 스택 및 구조

* **SLAM 맵** + **Nav2 경로 계획**
* **Docking 기능**으로 시작/종료 자동화
* TurtleBot4 입차용/출차용 2대 운용

#### ⚙️ 구현 내용

* 초기 undock → 주차 위치로 이동 → 주차 → 복귀 후 dock
* 출차 시 DB에서 차량번호 검색 후 해당 위치로 이동 → 출차 → 복귀

---

### 3-4. 🖥 GUI 및 InfluxDB 연동

#### 📌 기술 스택 및 구조

* PyQt GUI로 사용자/관리자 UI 제공
* InfluxDB에 차량번호, 위치, 상태, 시간 기록
* 차량번호 검색, 위치 기반 조회, 주차 이력 분석 기능 제공

#### ⚙️ 구현 내용

* 입출차 정보는 `line protocol` 포맷으로 DB에 전송
* 최근 30일 내 이력, 주차 위치 필터링, 번호 뒷자리 검색 지원

---

## 4. 핵심 코드 구현

### `raspi_monitor.py`

**역할**: 시스템 부하(CPU, 메모리, 네트워크 등) 측정 및 로그 기록<br>
**기능**: 이 도구를 통해 압축 이미지 전송 등 **경량화 실험의 수치 기반 근거 확보**<br>
* **기존 방식**: `htop`, `iftop` 등의 터미널 기반 툴로 수동 모니터링<br>
  → 실시간 변동이 심해 **객관적 비교 및 기록 어려움**, 로그 누락 발생
* **개선 방식**:<br>
  → Python 기반 자체 측정 도구 구현<br>
  → 전체 CPU 사용량, 특정 PID의 CPU 사용량, 메모리 사용량, 네트워크 전송량 등을
  **일정 주기로 자동 기록하여 CSV 저장**<br>
  → 다양한 설정에서 **정량 비교 가능**, 시스템 리소스 최적화 방향 수립 가능
 

### `detect_car_info.py`

**역할**: 차량 번호판 및 차종 인식, OCR 수행<br>
**기능**: YOLO + EasyOCR → 차종 분류 및 번호 추출 → DB 기록

* **YOLOv8**으로 차량 이미지에서 번호판 객체(BBOX)를 탐지<br>
  → 해당 BBOX 영역만 crop하여 OCR에 전달
* EasyOCR 적용 전, **crop된 이미지에 이진화 전처리(binary thresholding)** 수행<br>
  → 조명이나 그림자 등 주변 조건에 따라 번호판 인식률이 낮아지는 문제를 개선하기 위해 적용<br>
  → `cv2.threshold()` 또는 `cv2.adaptiveThreshold()`를 사용하여 텍스트 대비 향상<br>
  → OCR 실패율을 감소시켜 인식률 안정화
* EasyOCR 결과에 대해 **정규표현식(`\d{2,3}[가-힣]\d{4}`)** 필터링을 적용하여 유효성 검사<br>
  → 잘못된 인식 결과(예: 특수문자, 형식 오류 등) 제거
* 차량 정보(차종 + 번호판)는 JSON 형태로 구성하여 `/detect/car_info` 토픽으로 발행<br>
  → 예: `{"type": "EV", "car_plate": "123가4567"}`
* 동일 정보를 InfluxDB에도 기록하여 추후 GUI에서 입출차 기록 확인 가능


### `detect_yolo.py`

**역할**: 주차 구역 사인 탐지 및 위치, Depth 측정<br>
**기능**: YOLOv8으로 주차 사인 탐지 (예: 주차 영역, 주차금지, EV 구역, 장애인 전용 구역)
* **기존 방식**: YOLO 탐지 중심 픽셀(1점)의 Depth 값을 그대로 사용 → 측정 값이 불안정하고 노이즈 민감
* **개선 방식**:<br>
  → 탐지 중심 기준 `3x3` Depth 영역에서 **유효한 Depth 값만 추출**<br>
  → 해당 값들의 **중앙값(median)** 으로 거리 계산 → **노이즈 제거 + 안정적 거리 추정**<br>
  → Depth 측정 신뢰도 개선으로 주차 위치 추정 정확도 향상
* 계산된 3D 위치는 `/detect/object_info`로 발행 → 후속 노드에서 TF 변환 수행

### `detect_ps_front.py`

**역할**: 주차 구역 사인 감지 결과 기반 정밀 좌표 마킹<br>
**기능**: 정밀 좌표 마킹 → `sc_follow_waypoints.py` 토픽 발행
* `/detect/object_info` 토픽을 구독하여 탐지 결과 처리
* `pixel_to_3d()`로 복원된 위치를 TF(`camera_link → map`) 기준으로 변환
* `do_transform_point()`를 통해 map 좌표계로 변환하여 `/detect/object_map_pose` 발행
* 로봇 중심 기준 `-0.5m` 오프셋을 적용해 실제 주차 위치 보정
* **여러 TurtleBot 운용 시** `robot2` 네임스페이스 적용 → TF 충돌 방지 및 정확한 좌표 계산


### `sc_follow_waypoints.py`

**역할**: SLAM 기반 자율주행 경로 실행 및 도킹 제어<br>
**기능**: 주차공간 및 출차 위치까지 이동 → 회전 및 복귀 → Docking

* **`nav2_simple_commander`의 `BasicNavigator` 액션 클라이언트**를 활용해 여러 개의 waypoint를 순차적으로 주행<br>
  → `followWaypoints()`로 이동 지점 배열 처리
* 각 waypoint 도착 여부는 `navigator.isTaskComplete()` 및 `getFeedback()`을 통해 실시간 확인
* 입차 시, YOLO + Depth 기반 주차 사인 탐지 노드(`detect_ps_front.py`)에서 마킹된 좌표(`/detect/object_map_pose`)를 구독하여<br>
  → **waypoint 경로 중간에 주차 위치를 동적으로 삽입**하여 정밀 주차 수행
* 출차 시, DB에서 조회한 차량 위치로 이동 후 180도 회전 + 비동기 경고음 출력
* 경고음 출력 로직은 threading 기반 별도 노드와 연동되어 주행 중단 없이 비동기로 재생됨

### `parking_gui.py`

**역할**: PyQt 기반 사용자/관리자 인터페이스<br>
**기능**: 입출차 버튼, 차량번호 입력, DB 실시간 조회 기능 포함

---

## 5. 도전 과제와 문제 해결 방법

| 문제             | 해결 방안                              |
| -------------- | ---------------------------------- |
| YOLO 모델 리소스 부담 | YOLOv8n 사용 및 이미지 크기 축소 (320x320)   |
| OCR 인식률 저하     | 이진화 처리 및 정규표현식 필터로 보정              |
| TF 좌표 오차       | `baselink` 기준으로 보정 오프셋 적용          |
| 네트워크 과부하       | 압축 이미지 전송(compressed\_img) 구조로 경량화 |

---

## 6. 협업 내용 및 진행 과정

* **협업 내용**

  > YOLO 인식 결과를 OCR 및 GUI, 그리고 Navi 모듈과 연계해야 했기 때문에, 각 모듈 간 데이터 형식과 시간 지연을 최소화하기 위한 인터페이스 설계에 집중했습니다. 저는 경량화와 통합 측면을 중심으로 모델 학습뿐 아니라 시스템 전체가 동작 가능한 구조로 정리하고자 했습니다.
  > 따라서 RASPBERRYPI4에 원격접속하여 CPU, 네트워크 부하를 분석하기 위해 HTOP, IFTOP 모니터링 도구를 사용해보았으나 실시간 사용량의 변동 폭이 커 일관성 있는 비교가 어렵다고 판단하여 파이썬 코드를 통해 로그기록, 측정 및 분석을 할 수 있도록 코드를 구현하여 객관적이고 정량적으로 비교가 가능하게 되었고 이를 통해 시스템 경량화 작업을 수행하였습니다.

* **진행 과정**

  * YOLO 학습 및 이미지 최적화 담당
  * OCR 및 GUI 연동 팀원과 함께 데이터 처리 흐름 조율
  * SLAM 맵 최적화 및 주차 위치 기준점 리포지셔닝
  * compressed image 실험을 통한 네트워크 개선 지표 확보

---

## 7. 성과 및 결과물

* YOLOv8 기반 차량/주차공간 인식 성공
* OCR 기반 번호판 인식률 90% 이상 확보
* TF + Depth 기반 정밀 주차 수행
* InfluxDB 기반 실시간 차량 위치 및 이력 관리 성공
* GUI로 사용자 편의성 강화 + 관리자 기능 탑재
* 압축 이미지 실험을 통한 CPU/네트워크 사용량 \~90% 절감

---

## 8. 프로젝트 결과

* **입차/출차 프로세스 전체 자동화 시연 성공**
* **GUI, 인식, 제어, 이동, DB 연동을 통합한 시스템 구현**
* **YOLO + OCR + TF + Navi 전체 파이프라인 동작**
* **하드웨어/소프트웨어 리소스 경량화 실험 완료**

---

## 9. 개인적 성찰 및 배운 점

### 📌 인터페이스 설계 및 협업

* 센서 융합과 자율주행 제어 시스템 간의 **인터페이스 설계 감각 향상**
* 팀원 간 기술 격차 해소를 위한 **문서화 및 테스트 환경 공유의 중요성 인식**
* 복잡한 시스템 통합 상황에서 **데이터 흐름 설계 및 검증의 중요성** 체감

---

### ✅ 프로젝트를 통해 체득한 실무형 기술 역량

#### 🧠 ROS2 실시간 데이터 처리 및 최적화

* `image_transport/compressed` 방식 적용을 통한 네트워크 부하 감소
* 토픽 지연 최소화, **타임스탬프 동기화 유지** 등 실시간성 보장 전략 습득
* ROS2의 `callback`, `QoS`, `rclpy` 구조에 대한 실전 경험

#### 🧵 멀티스레딩 기반 비동기 처리

* Python `threading` 모듈로 **주행 로직과 사운드 출력 간 독립 제어 구조** 구현
* waypoint 진행 중에도 **경고음 재생이 끊김 없이 동작**
* 사용자 피드백을 위한 **청각/시각 동시 출력 구조 설계**

#### 🎥 YOLO/Depth 영상처리 최적화

* YOLOv8 입력 해상도(`320x320`)로 설정 후 전처리 최소화 → 연산 비용 절감
* Depth 중심 픽셀 단일값 대신 **`3x3` 영역 중앙값 사용** → 노이즈 제거 + 안정성 향상
* 영상 해석 정확도 및 처리 속도 간의 균형 조율 경험 확보

#### 🧭 TF 좌표 변환 및 네임스페이스 설계

* `lookup_transform()` + `do_transform_point()`로 **정밀 주차 좌표 산출**
* 주차 표지판 기준 `-0.5m` offset 적용하여 실제 위치 보정
* **다중 TurtleBot 운용**을 위한 네임스페이스 리맵 구조 설계 및 적용

#### 📊 Python 기반 시스템 부하 측정 도구 구현

* 기존 `htop`, `iftop`의 수동 측정 한계를 극복
* **CPU/메모리/네트워크 트래픽, PID별 사용량을 주기적으로 CSV로 기록**
* 다양한 설정에서의 부하를 **정량 분석**하여:

  * YOLO 입력 해상도
  * Depth 병합 여부
  * 이미지 압축 유무 등
* 시스템 최적화 방향을 **과학적으로 도출**하고 적용함


---
## 10. 개선 및 확장 아이디어

* **정기적인 SLAM 지도 갱신 자동화**: 주변 환경 변화 대응
* **차량 등록제와 연계된 예약 주차 시스템 구축**
* **CCTV 객체 인식 연동 → 보안 강화 및 사고 방지 기능 탑재**
* **CCTV 객체 인식 연동을 통해 입출차 차량수 확인(벡터 변화값 활용)**
* **음성 명령 기반 입출차 인터페이스로 고령자 접근성 향상**
* **아파트 세대별 주차대수 등록 및 확인**: 주차갈등문제 부분해소

---
