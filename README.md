# AutoPark Vision: AI 기반 스마트 자율주차 로봇 시스템

**ROS 2 + YOLOv8 + OCR 기반으로, 차량 번호판 인식 → 차량 분류 → 주차 및 출차까지 수행하는 자율주차 시스템을 구현했습니다.**
**전기차 수요 증가와 주차 공간 부족 문제를 해결하고자, `인식-판단-행동` 전 과정을 자동화한 TurtleBot 기반 주차 로봇 프로토타입을 구축했습니다.**

* 📅 **개발 기간**: 2025.06.25 \~ 07.04 (10일)
* 🧑‍🤝‍🧑 **인원 구성**: 7명
  **(본인 역할: YOLO 학습(주차공간 object detection), 성능 측정 및 경량화, 경고음 통합)**
* 🛠 **사용 기술**: ROS 2, YOLOv8, EasyOCR, OAK-D Pro, TurtleBot4, RPLiDAR, InfluxDB, PyQt
* ✅ **주요 기능**: 차량 번호판 인식 및 분류, 정밀 주차/출차, 실시간 GUI 및 DB 연동, 압축 이미지 기반 경량화

---

## 📑 프로젝트 개요

* **주제**: AutoPark Vision (스마트 자율주차 시스템)
* **목표**: 주차 수요 증가와 인력 문제를 해소하기 위한 자율주차 로봇 시스템 개발
* **팀원**: 7명

**🧑‍🤝‍🧑 팀원 역할 분담**

> | 이름           | 역할                                           |
> | ------------ | -------------------------------------------- |
> | **이세현(작성자)** | **YOLO 학습(주차공간 object detection), 성능 측정 및 경량화, 경고음 통합** |
> | 강인우          | OCR 기반 번호판 인식, Depth-TF 연동, Navi 연계          |
> | 이형연          | GUI 설계 및 OCR-GUI 통합, InfluxDB 구조 설계          |
> | 정서윤          | [팀장]SLAM 및 Navigation, 경고음 통합, GUI-SLAM 통합         |
> | 나승원          | YOLO 학습(번호판 object detection)          |
> | 이동기          | 자료조사 및 차량 훈련 학습          |
> | 홍진          | 자료조사, 영상편집         |


<br>

**📅 작업 일정**

> | 기간           | 작업 내용                         |
> | ------------ | ----------------------------- |
> | 06/25 \~ 06/26 | 기획 및 역할 분담                    |
> | 06/27 \~ 06/29 | YOLO 학습 및 OCR 파이프라인 구성        |
> | 06/30 \~ 07/01 | Navi 및 Depth-TF 연동, 통합 GUI 구현 |
> | 07/01 \~ 07/02 | 통합 테스트              |
> | 07/03 \~ 07/04  | 최종 발표 및 보고서 제출                |

---

## 1. 개발 배경 및 기획

전기차 시장이 급속히 성장하면서 실시간 주차 공간 확보와 효율적 운영에 대한 수요가 증가하고 있습니다. 특히 무인 자율주차 서비스는 노동력 절감과 안전성, 편의성 측면에서 주목받고 있습니다.

**AutoPark Vision 프로젝트**는 TurtleBot4와 OAK-D, LiDAR를 이용하여 차량 번호판 인식, 차종 분류, 위치 판단, 그리고 SLAM 기반 자율주차·출차 기능을 통합한 **스마트 자율주차 로봇 시스템**을 구현하는 것이 목표였습니다.

### 🔧 핵심 기능

1. 차량 번호판 인식 및 차종 분류 (YOLO + OCR)
2. 주차 위치 판단 및 자율이동 (Nav2 + SLAM + TF)
3. GUI 기반 입출차 및 DB 기록 관리

### 🧭 프로세스

![시스템 플로우 다이어그램](https://github.com/user-attachments/assets/example_autopark_diagram.jpg)

---

## 2. 사용 장비 & 기술 스택

![image](https://github.com/user-attachments/assets/example_autopark_tech.jpg)

| 분류     | 기술                                        |
| ------ | ----------------------------------------- |
| 언어     | Python                                    |
| 로봇 제어  | ROS 2 (Humble), Nav2, TurtleBot4, RPLIDAR |
| 객체 인식  | YOLOv8 (주차공간/차량 번호판/차종)                   |
| 문자 인식  | EasyOCR (번호판 추출 및 정규표현식 필터링)              |
| 센서     | OAK-D Pro (RGB-D), RPLiDAR                |
| GUI 설계 | PyQt                                      |
| DB 기록  | InfluxDB (차량 입출차 시계열 기록)                  |
| 최적화    | 압축 이미지 전송 (image_transport), Oak-D Pro.yaml 파라미터 설정               |

---

## 3. 주요 기능 구현 과정

### 3-1. 🚘 차량 번호판 인식 및 차종 분류

#### 📌 기술 스택 및 구조

* **YOLOv8** → 번호판 객체 탐지 및 차종 분류 (EV, 일반, 장애인차량)
* **EasyOCR** → 번호판 영역 내 문자 인식 및 유효성 검사
* 차량 정보: `{"type": "disabled", "car_plate": "123가4568"}` 형태로 DB 저장

#### ⚙️ 구현 내용

* YOLOv8을 사용하여 4클래스 번호판/차종 구분 모델 학습
* EasyOCR 결과에 정규표현식(`\d{2,3}[가-힣]\d{4}`) 적용
* OCR/차종 정보를 기반으로 적합한 주차 공간(A-1\~C-2) 결정

---

### 3-2. 📏 Depth-TF 기반 주차 위치 정밀 제어

#### 📌 기술 스택 및 구조

* **OAK-D** Depth 정보를 이용한 중심 거리 추정
* **TF 좌표 변환** (`do_transform_point`)을 통해 로봇 좌표계 기준 정밀 주차

#### ⚙️ 구현 내용

* YOLO로 검출된 주차 공간 좌표를 기준으로 3x3 영역 Depth 측정
* 중앙값 기반 거리 추정 후 `baselink` 기준으로 0.5m 전진
* 주차 완료 후 180도 회전 및 음성 출력

---

### 3-3. 🧭 SLAM 기반 입차/출차 자율주행

#### 📌 기술 스택 및 구조

* **SLAM 맵** + **Nav2 경로 계획**
* **Docking 기능**으로 시작/종료 자동화
* TurtleBot4 입차용/출차용 2대 운용

#### ⚙️ 구현 내용

* 초기 undock → 주차 위치로 이동 → 주차 → 복귀 후 dock
* 출차 시 DB에서 차량번호 검색 후 해당 위치로 이동 → 출차 → 복귀

---

### 3-4. 🖥 GUI 및 InfluxDB 연동

#### 📌 기술 스택 및 구조

* PyQt GUI로 사용자/관리자 UI 제공
* InfluxDB에 차량번호, 위치, 상태, 시간 기록
* 차량번호 검색, 위치 기반 조회, 주차 이력 분석 기능 제공

#### ⚙️ 구현 내용

* 입출차 정보는 `line protocol` 포맷으로 DB에 전송
* 최근 30일 내 이력, 주차 위치 필터링, 번호 뒷자리 검색 지원

---

## 4. 핵심 코드 구현

### `raspi_monitor.py`

**역할**: 시스템 부하(ex. CPU, 네트워크 등) 측정 및 csv 기록
**기능**: 시스템 경량화

### `detect_car_info.py`

**역할**: 차량 번호판 및 차종 인식, OCR 수행
**기능**: YOLO + EasyOCR → 차종 분류 및 번호 추출 → DB 기록


### `detect_parking.py`

**역할**: 주차 공간 탐지 및 위치 추정
**기능**: YOLO + Depth 기반 거리 추정 → TF 변환 좌표 계산

### `sc_follow_waypoints.py`

**역할**: SLAM 기반 자율이동
**기능**: 주차공간 및 출차 위치까지 이동 → 회전 및 복귀 → Docking

### `parking_gui.py`

**역할**: PyQt 기반 사용자/관리자 인터페이스
**기능**: 입출차 버튼, 차량번호 입력, DB 실시간 조회 기능 포함

---

## 5. 도전 과제와 문제 해결 방법

| 문제             | 해결 방안                              |
| -------------- | ---------------------------------- |
| YOLO 모델 리소스 부담 | YOLOv8n 사용 및 이미지 크기 축소 (320x320)   |
| OCR 인식률 저하     | 이진화 처리 및 정규표현식 필터로 보정              |
| TF 좌표 오차       | `baselink` 기준으로 보정 오프셋 적용          |
| 네트워크 과부하       | 압축 이미지 전송(compressed\_img) 구조로 경량화 |

---

## 6. 협업 내용 및 진행 과정

* **협업 내용**

  > YOLO 인식 결과를 OCR 및 GUI, 그리고 Navi 모듈과 연계해야 했기 때문에, 각 모듈 간 데이터 형식과 시간 지연을 최소화하기 위한 인터페이스 설계에 집중했습니다. 저는 경량화와 통합 측면을 중심으로 모델 학습뿐 아니라 시스템 전체가 동작 가능한 구조로 정리하고자 했습니다.
  > 따라서 RASPBERRYPI4에 원격접속하여 CPU, 네트워크 부하를 분석하기 위해 HTOP, IFTOP 모니터링 도구를 사용해보았으나 실시간 사용량의 변동 폭이 커 일관성 있는 비교가 어렵다고 판단하여 파이썬 코드를 통해 로그기록, 측정 및 분석을 할 수 있도록 코드를 구현하여 객관적이고 정량적으로 비교가 가능하게 되었고 이를 통해 시스템 경량화 작업을 수행하였습니다.

* **진행 과정**

  * YOLO 학습 및 이미지 최적화 담당
  * OCR 및 GUI 연동 팀원과 함께 데이터 처리 흐름 조율
  * SLAM 맵 최적화 및 주차 위치 기준점 리포지셔닝
  * compressed image 실험을 통한 네트워크 개선 지표 확보

---

## 7. 성과 및 결과물

* YOLOv8 기반 차량/주차공간 인식 성공
* OCR 기반 번호판 인식률 90% 이상 확보
* TF + Depth 기반 정밀 주차 수행
* InfluxDB 기반 실시간 차량 위치 및 이력 관리 성공
* GUI로 사용자 편의성 강화 + 관리자 기능 탑재
* 압축 이미지 실험을 통한 CPU/네트워크 사용량 \~90% 절감

---

## 8. 프로젝트 결과

* **입차/출차 프로세스 전체 자동화 시연 성공**
* **GUI, 인식, 제어, 이동, DB 연동을 통합한 시스템 구현**
* **YOLO + OCR + TF + Navi 전체 파이프라인 동작**
* **하드웨어/소프트웨어 리소스 경량화 실험 완료**

---

## 9. 개인적 성찰 및 배운 점

* 센서 융합과 자율주행 제어 시스템 간의 인터페이스 설계 감각 향상
* 팀원 간 기술 격차를 메우기 위한 문서화와 테스트 환경 공유의 중요성 인식
* CPU/네트워크 자원의 경량화 실험을 통해 정량적인 성능 평가 경험 확보

---
## 10. 개선 및 확장 아이디어

* **정기적인 SLAM 지도 갱신 자동화**: 주변 환경 변화 대응
* **차량 등록제와 연계된 예약 주차 시스템 구축**
* **CCTV 객체 인식 연동 → 보안 강화 및 사고 방지 기능 탑재**
* **CCTV 객체 인식 연동을 통해 입출차 차량수
*
* 인(벡터 변화값 활용)**
* **음성 명령 기반 입출차 인터페이스로 고령자 접근성 향상**
* **아파트 세대별 주차대수 등록 및 확인**: 주차갈등문제 부분해소

---
